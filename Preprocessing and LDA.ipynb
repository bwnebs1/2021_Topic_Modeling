{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from gensim import corpora\n",
    "from gensim import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='/Volumes/GoogleDrive/내 드라이브/2021-2/커텍마/과제/Final Project/FINAL/'\n",
    "csv='.csv'\n",
    "\n",
    "company_list=['당근마켓','라인플러스','롯데정보통신','무신사','비바리퍼블리카','삼성SDS','신세계아이앤씨',\n",
    "              '우아한형제들','카카오','크래프톤','티맥스소프트','포스코ICT','하이퍼커넥트','한국IBM','한글과컴퓨터',\n",
    "             'AhnLab','COUPANG','LGCNS','NAVER','NCSOFT']\n",
    "\n",
    "review_list=[]\n",
    "career_list=[]\n",
    "life_list=[]\n",
    "money_list=[]\n",
    "culture_list=[]\n",
    "manager_list=[]\n",
    "overall_list=[]\n",
    "sentiment_list=[]\n",
    "\n",
    "for i in range(len(company_list)):\n",
    "    data=pd.read_csv(path+company_list[i]+csv, header=0, index_col=0)\n",
    "    data['overall']=np.mean(data,axis=1)\n",
    "    review_list.append(list(data.review))\n",
    "    career_list.append(list(data.career))\n",
    "    life_list.append(list(data.life))\n",
    "    money_list.append(list(data.money))\n",
    "    culture_list.append(list(data.culture))\n",
    "    manager_list.append(list(data.manager))\n",
    "    overall_list.append(list(data.overall))\n",
    "\n",
    "for i in range(len(company_list)):\n",
    "    for j in range(len(overall_list[i])):\n",
    "        if overall_list[i][j]>3.5:\n",
    "            sentiment_list.append('positive')\n",
    "        elif overall_list[i][j]<2.5:\n",
    "            sentiment_list.append('negative')\n",
    "        else: sentiment_list.append('neutral')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import konlpy.tag\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(company_list)):\n",
    "    for j in range(len(review_list[i])):\n",
    "        review_list[i][j]=re.sub(r'[^\\s\\w\\d]',' ', review_list[i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ijaehwan/opt/anaconda3/lib/python3.8/site-packages/konlpy/tag/_okt.py:16: UserWarning: \"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.\n",
      "  warn('\"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.')\n"
     ]
    }
   ],
   "source": [
    "twitter=konlpy.tag.Twitter()\n",
    "nva_word=[[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]]\n",
    "dummy_list=[]\n",
    "\n",
    "for i in range(len(company_list)):\n",
    "    for j in range(len(review_list[i])):\n",
    "        twitter_morphs=twitter.pos(review_list[i][j])\n",
    "        for word, pos in twitter_morphs:\n",
    "            if pos == 'Noun' or pos == 'Verb' or pos == 'Adjective':\n",
    "                dummy_list.append(word)\n",
    "        nva_word[i].append(dummy_list)\n",
    "        dummy_list=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_nva=[]\n",
    "for i in range(len(nva_word)):\n",
    "    for j in range(len(nva_word[i])):\n",
    "        unique_nva.append(list(set(nva_word[i][j])))\n",
    "    \n",
    "uni_nva=[]\n",
    "for i in range(len(unique_nva)):\n",
    "    for j in range(len(unique_nva[i])):\n",
    "        uni_nva.append(unique_nva[i][j])\n",
    "        \n",
    "uni_nva=set(uni_nva)\n",
    "\n",
    "stopword=['회사','라벨','있는','하는', '게임']\n",
    "\n",
    "#전처리\n",
    "for i in range(len(nva_word)):\n",
    "    for j in range(len(nva_word[i])):\n",
    "        for word in uni_nva:\n",
    "            if len(word)<2:\n",
    "                while word in nva_word[i][j]: nva_word[i][j].remove(word)\n",
    "            if word in stopword:\n",
    "                while word in nva_word[i][j]: nva_word[i][j].remove(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NounVerbAdj</th>\n",
       "      <th>career</th>\n",
       "      <th>life</th>\n",
       "      <th>money</th>\n",
       "      <th>culture</th>\n",
       "      <th>manager</th>\n",
       "      <th>overall</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[밸류, 인정, 받고, 방황]</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2.8</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[들어온지, 마안, 됐지만, 좋아, 보여요]</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[열정, 실력, 갖추는, 조직]</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[로켓, 성장하는]</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[워워벨, 보장, 되는]</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12295</th>\n",
       "      <td>[다닐만]</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3.2</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12296</th>\n",
       "      <td>[팀바팀]</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3.8</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12297</th>\n",
       "      <td>[개임, 특성, 단점, 빼면, 좋음]</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4.2</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12298</th>\n",
       "      <td>[복지, 좋음]</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2.4</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12299</th>\n",
       "      <td>[복지, 좋은]</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12300 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    NounVerbAdj career life money culture manager overall  \\\n",
       "0              [밸류, 인정, 받고, 방황]      3    3     3       3       2     2.8   \n",
       "1      [들어온지, 마안, 됐지만, 좋아, 보여요]      5    5     5       5       5     5.0   \n",
       "2             [열정, 실력, 갖추는, 조직]      5    5     5       5       5     5.0   \n",
       "3                    [로켓, 성장하는]      5    5     5       5       5     5.0   \n",
       "4                 [워워벨, 보장, 되는]      4    3     5       5       3     4.0   \n",
       "...                         ...    ...  ...   ...     ...     ...     ...   \n",
       "12295                     [다닐만]      3    3     4       3       3     3.2   \n",
       "12296                     [팀바팀]      4    4     4       4       3     3.8   \n",
       "12297      [개임, 특성, 단점, 빼면, 좋음]      3    5     5       4       4     4.2   \n",
       "12298                  [복지, 좋음]      2    3     4       2       1     2.4   \n",
       "12299                  [복지, 좋은]      3    3     4       3       2     3.0   \n",
       "\n",
       "      sentiment  \n",
       "0       neutral  \n",
       "1      positive  \n",
       "2      positive  \n",
       "3      positive  \n",
       "4      positive  \n",
       "...         ...  \n",
       "12295   neutral  \n",
       "12296  positive  \n",
       "12297  positive  \n",
       "12298  negative  \n",
       "12299   neutral  \n",
       "\n",
       "[12300 rows x 8 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_nva=[]\n",
    "all_career=[]\n",
    "all_life=[]\n",
    "all_money=[]\n",
    "all_culture=[]\n",
    "all_manager=[]\n",
    "all_overall=[]\n",
    "for i in range(len(nva_word)):\n",
    "    all_nva=all_nva+nva_word[i]\n",
    "    all_career=all_career+career_list[i]\n",
    "    all_life=all_life+life_list[i]\n",
    "    all_money=all_money+money_list[i]\n",
    "    all_culture=all_culture+culture_list[i]\n",
    "    all_manager=all_manager+manager_list[i]\n",
    "    all_overall=all_overall+overall_list[i]\n",
    "    \n",
    "dataframe_list=[all_nva, all_career, all_life, all_money, all_culture, all_manager, all_overall, sentiment_list]\n",
    "df=pd.DataFrame(dataframe_list)\n",
    "df=df.T\n",
    "df.columns=['NounVerbAdj','career','life','money','culture','manager','overall','sentiment']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('Preprocessed Dataframe.csv', index=False, sep = chr(int(\"15\")))\n",
    "\n",
    "\n",
    "#불러올 때도 구분자를 꼭 기억하자 chr(int(\"15\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#여기까지 전처리#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_doc_word_matrix(docs):\n",
    "    dictionary = corpora.Dictionary(docs)\n",
    "    corpus = []\n",
    "    for doc in docs:\n",
    "        bow = dictionary.doc2bow(doc)\n",
    "        corpus.append(bow)\n",
    "\n",
    "    return corpus, dictionary\n",
    "\n",
    "corpus, dictionary = build_doc_word_matrix(df.iloc[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique tokens: 6114\n",
      "Number of documents: 12300\n"
     ]
    }
   ],
   "source": [
    "print('Number of unique tokens: %d' % len(dictionary))\n",
    "print('Number of documents: %d' % len(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_topic_words(model):\n",
    "    f = open('topic_results_test.txt','w')\n",
    "    for topic_id in range(model.num_topics):\n",
    "        word_probs = model.show_topic(topic_id, 2)\n",
    "        print(\"Topic ID: {}\".format(topic_id))\n",
    "        f.write(str(topic_id)+'\\n')\n",
    "        for word, prob in word_probs:\n",
    "            print(\"\\t{}\\t{}\".format(word, prob))\n",
    "            f.write(str(word)+'\\t'+str(prob)+'\\n')\n",
    "        print(\"\\n\")\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = models.ldamodel.LdaModel(corpus, num_topics=5, id2word=dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#토픽모델링 (1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic ID: 0\n",
      "\t복지\t0.11655901372432709\n",
      "\t보장\t0.07036088407039642\n",
      "\n",
      "\n",
      "Topic ID: 1\n",
      "\t좋은\t0.1800929307937622\n",
      "\t최고\t0.04122032970190048\n",
      "\n",
      "\n",
      "Topic ID: 2\n",
      "\t괜찮은\t0.02815878950059414\n",
      "\t직원\t0.023537902161478996\n",
      "\n",
      "\n",
      "Topic ID: 3\n",
      "\t사람\t0.03181305155158043\n",
      "\t문화\t0.03113090619444847\n",
      "\n",
      "\n",
      "Topic ID: 4\n",
      "\t좋음\t0.03632063418626785\n",
      "\t안정\t0.020881904289126396\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_topic_words(lda_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model_2 = models.ldamodel.LdaModel(corpus, num_topics=2, id2word=dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_topic_words_2(model):\n",
    "    f = open('topic_results_test.txt','w')\n",
    "    for topic_id in range(model.num_topics):\n",
    "        word_probs = model.show_topic(topic_id, 2)\n",
    "        print(\"Topic ID: {}\".format(topic_id))\n",
    "        f.write(str(topic_id)+'\\n')\n",
    "        for word, prob in word_probs:\n",
    "            print(\"\\t{}\\t{}\".format(word, prob))\n",
    "            f.write(str(word)+'\\t'+str(prob)+'\\n')\n",
    "        print(\"\\n\")\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#토픽모델링 (2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic ID: 0\n",
      "\t좋은\t0.06945085525512695\n",
      "\t복지\t0.043710656464099884\n",
      "\n",
      "\n",
      "Topic ID: 1\n",
      "\t보장\t0.03151746839284897\n",
      "\t되는\t0.027433065697550774\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_topic_words_2(lda_model_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4614"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[df['sentiment']=='positive'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3515"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[df['sentiment']=='negative'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4171"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[df['sentiment']=='neutral'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "authorship_tag": "ABX9TyPGz7SCgcmA9tFR1eVBYkHm",
   "name": "Untitled0.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
